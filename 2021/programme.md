---
layout: cvmp-default
title: Conference Programme
year: 2021
---

{% include_relative covid-19.md %}

### Programme ###

<strong>Programme booklet:</strong>
[CVMP 2021 Programme (5.8 MB)]({{ site.url }}/files/2021/CVMP2021-programme.pdf)

<strong>Conference proceedings:</strong>
[ACM Digital Library](https://doi.org/10.1145/3485441){:target="_blank"}

<div class="col-12 col-sm-12 col-lg-12">
	<a name="monday"></a>
	<div class="panel panel-default">
		<div class="panel-heading"><b>Monday 6th December 2021</b></div>
		<table class="table table-striped">
			<tr>
				<td>09:00</td>
				<td><b>Registration opens with Coffee</b></td>
			</tr>
			<tr>
				<td>09:30</td>
				<td><b>Chairs’ Welcome</b><br/>Christian Richardt, <i>University of Bath</i> (Conference Co-Chair)</td>
			</tr>
			<tr>
				<td>09:40</td>
				<td><b>Papers and Industry Talks Session 1: Bring on the colours!</b><br/>
					<ul>
						<li>Semantic-driven Colorization<br/><i>Man M. Ho (Hosei University), Lu Zhang (INSA Rennes), Alexander Raake (TU Ilmenau), Jinjia Zhou (Hosei University)</i></li>
						<li>Arnold 7 update<br/><i>Frederic Servant (Autodesk)</i></li>
						<li>Photometric Stereo with Area Lights for Lambertian Surfaces<br/><i>Jiangbin Gan (University of Marburg), Thorsten Thormählen (University of Marburg)</i></li>
						<li>Material acquisition and editing<br/><i>Valentin Deschaintre (Adobe Research)</i></li>
					</ul>
				</td>
			</tr>
			<tr>
				<td>11:00</td>
				<td><b>Coffee Break</b><br/><i>Poster presenters put up posters</i></td>
			</tr>	
			<tr>
				<td>11:30</td>
				<td><a href="/2021/keynotes/#CO"><b>Keynote: 3D Digital Reality – Modeling for Perception</b></a><br/>Cengiz Öztireli, <i>University of Cambridge</i></td>
			</tr>
			<tr>
				<td>12:30</td>
				<td><b>Spotlight Session</b><br/>
					<ul>
						<li>One-shot SVBRDF Estimation Including Anisotropic Material<br/><i>Nozomu Terada (Tokyo University of Agriculture and Technology), Ikuko Shimizu (Tokyo University of Agriculture and Technology)</i></li>
						<li>AURealnessGAN - An Architecture that Enables Manipulation of FACS Action Units in Face Image Generation<br/><i>Koyo Ishihara (Tokyo University of Agriculture and Technology), Ikuko Shimizu (Tokyo University of Agriculture and Technology), Akio Sashima (National Institute of Advanced Industrial Science and Technology), Koichi Kurumatani (National Institute of Advanced Industrial Science and Technology)</i></li>
						<li>A Step Towards Automating the Synthesis of a Scene Script<br/><i>Américo Pereira (INESC TEC), Ricardo Carvalho (FEUP), Pedro Carvalho (INESC TEC and Universidade do Porto), Luís Corte-Real (FEUP)</i></li>
						<li>Look-Up-Table Mystified<br/><i>Jurgen Stauder (InterDigital), Patrick Morvan (InterDigital), Angelo Mazzante (InterDigital), Anita Orhand (InterDigital), John Frith (MPC)</i></li>
						<li>Spatio-temporal algorithm for 3D sequences noise reduction<br/><i>Ljubomir Jovanov (UGent)</i></li>
						<li>Human Point Cloud Generation using Deep Learning<br/><i>Ryan Spick (University of York)</i></li>
						<li>Learning semantic object segmentation for video post-production<br/><i>Flavien Jourdren (InterDigital), Emmanuel Jolly (InterDigital R&D France), Claire-Helene Demarty (Technicolor), Frederic Lefebvre (InterDigital), Pierre Hellier (InterDigital (Technicolor))</i></li>
						<li>Image Super-Resolution via Hierarchical Attention-Based Multi-References Sampling<br/><i>Marco Pesavento (University of Surrey), Marco Volino (University of Surrey), Adrian Hilton (University of Surrey)</i></li>
						<li>Demo: Video Provenance Network for Robust Content Attribution<br/><i>Alexander Black (University of Surrey), Tu Bui (University of Surrey), Simon Jenni (Adobe Research), Viswanathan (Vishy) Swaminathan (Adobe), John Collomosse (Adobe Research)</i></li>
					</ul>
				</td>
			</tr>
			<tr>
				<td>12:40</td>
				<td><b>Lunch, Demo and Short Papers</b></td>
			</tr>
			<tr>
				<td>14:30</td>
				<td><b>Industry Special Session on Digital Humans</b><br/>
					<ul>
						<li>Volumetric video at the intersection of visual effects and virtual production<br/><i>Juraj Tomori (dimension), Charles Dupont (dimension), George Ash (dimension), Mike Pelton (dimension)</i></li>
						<li>High-Performance Multi-Camera Systems for Volumetric Capture and 4D Face/Body Scanning<br/><i>Andrew Searle (IO Industries Inc)</i></li>
						<li>The Creation of 3D Human Datasets for CV Research<br/><i>Lukas Lamprecht (Renderpeople)</i></li>						
					</ul>
				</td>
			</tr>		
			<tr>
				<td>15:30</td>
				<td><b>Coffee Break</b></td>
			</tr>	
			<tr>
				<td>16:00</td>
				<td><a href="/2021/keynotes/#DC"><b>Keynote: Creating Presence in Mixed Reality and the Metaverse</b></a><br/>Darren Cosker, <i>Microsoft</i></td>
			</tr>
			<tr>
				<td>17:00</td>
				<td><b>Networking Reception</b></td>
			</tr>
		</table>
	</div>
	<a name="tuesday"></a>
	<div class="panel panel-default">
		<div class="panel-heading"><b>Tuesday 7th December 2021</b></div>
		<table class="table table-striped">
			<tr>
				<td>09:00</td>
				<td><b>Registration opens with Coffee</b></td>
			</tr>
			<tr>
				<td>09:30</td>
				<td><b>Papers and Industry Talks Session 2: And action!</b><br/>
					<ul>
						<li>Automatic Camera Control and Directing with an Ultra-High-Definition Collaborative Recording System<br/><i>Bram Vanherle (Hasselt University), Tim Vervoort (Hasselt University), Nick Michiels (Hasselt University), Philippe Bekaert (Hasselt University)</i></li>
						<li>Contact-rich simulation in NVIDIA Omniverse<br/><i>Kier Storey and Michelle Lu (NVIDIA)</i></li>
						<li>FacialFilmroll: High-resolution multi-shot video editing<br/><i>Bharath Bhushan Damodaran (InterDigital R&D), Emmanuel Jolly (InterDigital R&D France), Gilles Puy (In his own name), Philippe-Henri Gosselin (InterDigital), Cédric Thébault (InterDigital), Junghyun Ahn (InterDigital), Tim Christensen (In his own name), Paul Ghezzo (In his own name), Pierre Hellier (InterDigital (Technicolor))</i></li>
						<li>Foundry and Machine Learning<br/><i>Ben Kent (Foundry)</i></li>
					</ul>
				</td>
			</tr>
			<tr>
				<td>10:50</td>
				<td><b>Coffee Break</b></td>
			</tr>	
			<tr>
				<td>11:20</td><td><a href="/2021/keynotes/#ST"><b>Keynote: Learning to Capture and Synthesise 3D Humans in 3D Scene</b></a><br/>Siyu Tang, <i>ETH Zürich</i></td>
			</tr>
			<tr>
				<td>12:20</td>
				<td><b>Lunch and Short Papers</b></td>
			</tr>
			<tr>
				<td>14:00</td>
				<td><b>Papers and Industry Talks Session 3: Gimme the data!</b><br/>
					<ul>
						<li>Depth Estimation from a Single Omnidirectional Image using Domain Adaptation<br/><i>Yihong Wu (The University of Southampton ECS VLC Group), Yuwen Heng (University of Southampton), Mahesan Niranjan (University of Southampton), Hansung Kim (University Of Southampton)</i></li>
						<li>VPN: Video Provenance Network for Robust Content Attribution<br/><i>Alexander Black (University of Surrey), Tu Bui (University of Surrey), Simon Jenni (Adobe Research), Viswanathan (Vishy) Swaminathan (Adobe), John Collomosse (Adobe Research)</i></li>
						<li>High-fidelity procedural data synthesis for validation and training of perception function<br/><i>Oliver Grau (Intel), Korbinian Hagn (Intel)</i></li>
						<li>Speech-Driven Conversational Agents using Conditional Flow-VAEs<br/><i>Sarah Taylor (University of East Anglia), Jonathan Windle (University of East Anglia), David Greenwood (University of East Anglia), Iain Matthews (Carnegie Mellon University)</i></li>
					</ul>
				</td>
			</tr>
			<tr>
				<td>15:20</td>
				<td><b>Coffee Break</b></td>
			</tr>
			<tr>
				<td>15:50</td>
				<td><a href="/2021/keynotes/#TR"><b>Keynote: Perceptually-inspired VR Image Synthesis</b></a><br/>Tobias Ritschel, <i>University College London</i></td>
			</tr>
			<tr>
				<td>16:50</td>
				<td><b>Prizes, Announcements and Closing</b><br/>Rafał Mantiuk, <i>University of Cambridge</i> (Conference Co-Chair)</td>
			</tr>
		</table>
	</div>
</div>
